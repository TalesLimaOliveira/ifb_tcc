# ğŸŒŸ Trabalho de ConclusÃ£o de Curso - Instituto Federal de BrasÃ­lia ğŸŒŸ

## RECONHECIMENTO E TRADUÃ‡ÃƒO DE FRASES EM LIBRAS UTILIZANDO REDES NEURAIS

<p align="center">
    <img src="https://img.shields.io/badge/Language-Python-blue?logo=python" alt="Language">
    <img src="https://img.shields.io/badge/Language-Julia-purple?logo=julia" alt="Language">
    <img src="https://img.shields.io/badge/Status-Active-success" alt="Status">
</p>


## ğŸ‘¨â€ğŸ« Orientador
- **Raimundo Vasconcelos**

## ğŸ‘¨â€ğŸ“ Aluno
- **[Tales Oliveira](https://github.com/TalesLimaOliveira)**

---

## ğŸ“š DescriÃ§Ã£o
Este projeto tem como objetivo desenvolver uma rede neural profunda que utiliza tÃ©cnicas de visÃ£o computacional para o reconhecimento e traduÃ§Ã£o de gestos e frases completas em LIBRAS (LÃ­ngua Brasileira de Sinais). Diferentemente de soluÃ§Ãµes existentes que se concentram na traduÃ§Ã£o de sinais ou letras isoladas, esta proposta busca criar um sistema que compreenda e traduza frases de forma contÃ­nua, e em tempo real, levando em consideraÃ§Ã£o o contexto dos sinais previamente realizados.

# LIBRAS Sign Recognition

Reconhecimento de sinais em LIBRAS a partir de vÃ­deos usando MediaPipe e TensorFlow.

## Estrutura

- `data/raw_videos/`: vÃ­deos originais em .mp4
- `data/landmarks/`: arquivos .parquet com landmarks extraÃ­dos
- `data/train.csv`: metadados para treinamento
- `src/`: scripts Python para extraÃ§Ã£o, preparaÃ§Ã£o e modelagem
- `notebooks/`: notebooks para experimentaÃ§Ã£o e treinamento

## Como usar
0. Crie um ambiente virtual:

   ```
   py -3.10 -m venv venv
   venv\Scripts\activate
   ```

1. Instale as dependÃªncias:
   ```
   pip install -r requirements.txt
   ```

2. Extraia os landmarks dos vÃ­deos:
   ```
   python src/extract_landmarks.py --input_dir data/raw_videos --output_dir data/landmarks
   ```

3. Prepare o arquivo `train.csv` com os metadados.

4. Treine o modelo usando o notebook em `notebooks/train_model.ipynb`.